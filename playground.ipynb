{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eefaf6b5-8d57-40d2-8412-3569af78d132",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets.dataset_dict import DatasetDict\n",
    "from datasets import Dataset\n",
    "\n",
    "import utils.dataset_processors as dataset_processors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "995ee92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_names(model_name):\n",
    "    return {\n",
    "        'distillbert': 'distilbert-base-uncased', # 66M\n",
    "        'xlnet': 'xlnet-base-cased', # 110M\n",
    "        'bert': 'bert-base-uncased', # 110M\n",
    "        'roberta': 'roberta-base', # 125M\n",
    "        'albert': 'albert-base-v2', # 11M\n",
    "        'electra': 'google/electra-small-discriminator', # 14M\n",
    "        'big-bird': 'google/bigbird-roberta-base', # 125M\n",
    "        'longformer': 'allenai/longformer-base-4096' # 149M\n",
    "    }[model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f53784a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model name for tokenizer and also the saved model name\n",
    "plm = 'xlnet'\n",
    "model_name = get_model_names(plm)\n",
    "\n",
    "# Add boolean for sentence segmentation:\n",
    "segment_sentences = True\n",
    "\n",
    "# Add filename that will be saved later:\n",
    "saved_model_file = f'{plm}-finetuned-segmented'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fb33c60-2870-4925-a7a6-d021c3f6ff01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "datafile = \"data/essays/essays.csv\"\n",
    "dataset = dataset_processors.load_essays_df(datafile)\n",
    "\n",
    "# Split the dataset (6:2:2)\n",
    "train_data, temp_data = train_test_split(dataset, train_size=0.6, random_state=42)\n",
    "validation_data, test_data = train_test_split(temp_data, train_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "454825b8-eb4a-499d-a7f7-2235941bd74a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EXT', 'NEU', 'AGR', 'CON', 'OPN']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the Big 5 labels\n",
    "column_names = list(train_data.columns)\n",
    "labels = [label for label in column_names if label not in ['user','text','token_len']]\n",
    "\n",
    "# Forward and backward mapping\n",
    "id2label = {idx:label for idx,label in enumerate(labels)}\n",
    "label2id = {label:idx for idx,label in enumerate(labels)}\n",
    "\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b7193809",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Import the model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    problem_type = \"multi_label_classification\",\n",
    "    num_labels = len(labels),\n",
    "    id2label = id2label,\n",
    "    label2id = label2id,\n",
    "    use_mems_eval=False\n",
    ")\n",
    "\n",
    "if model_name == 'xlnet':\n",
    "    model.config.use_mems_train = False\n",
    "    model.config.use_mems_eval = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e37b9a3d-9c80-46e8-b6ce-3008f87373fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from essay to sentences\n",
    "def split_text_with_labels(row):\n",
    "    \n",
    "    # Split sentences\n",
    "    sentences = re.split(r\"(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|\\!)\\s\", row['text'])\n",
    "\n",
    "    return [{\n",
    "        'text': sentence,\n",
    "        'EXT': row['EXT'],\n",
    "        'NEU': row['NEU'],\n",
    "        'AGR': row['AGR'],\n",
    "        'CON': row['CON'],\n",
    "        'OPN': row['OPN']\n",
    "    }\n",
    "        for sentence in sentences       \n",
    "    ]\n",
    "\n",
    "def transform_dataframe(old_dataframe):\n",
    "\n",
    "    # Begin the split\n",
    "    split_data = []\n",
    "    \n",
    "    for _, row in old_dataframe.iterrows():\n",
    "        split_data.extend(split_text_with_labels(row))\n",
    "        \n",
    "    return pd.DataFrame(split_data)\n",
    "\n",
    "if segment_sentences:\n",
    "    train_data = transform_dataframe(train_data)\n",
    "    test_data = transform_dataframe(test_data)\n",
    "    validation_data = transform_dataframe(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d724425-a30b-479b-bac7-c10b2cc9e875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text  EXT  NEU  AGR  CON  OPN\n",
      "0                                     I am tired now.    1    0    1    0    1\n",
      "1              I don't know what I should talk about.    1    0    1    0    1\n",
      "2                             I like this assignment.    1    0    1    0    1\n",
      "3                               Wonder when it's due?    1    0    1    0    1\n",
      "4    Kristi Urey is the most beautiful person I know.    1    0    1    0    1\n",
      "5                                         I love you.    1    0    1    0    1\n",
      "6   I mean I love her with all of my heart, mind, ...    1    0    1    0    1\n",
      "7                   I like psychology in high school.    1    0    1    0    1\n",
      "8               It was very interesting and personal.    1    0    1    0    1\n",
      "9                 That draws people in or so I think.    1    0    1    0    1\n",
      "10                 Psychology is the food of the sea.    1    0    1    0    1\n",
      "11                            My roommate's a weirdo.    1    0    1    0    1\n",
      "12             He wears a hat to watch Conan O'Brien.    1    0    1    0    1\n",
      "13  My other roommate got his computer from Dell t...    1    0    1    0    1\n",
      "14                                     I like Kristi.    1    0    1    0    1\n",
      "15  I may not be a smart man, but I know what love...    1    0    1    0    1\n",
      "16  Someone's going to be sorry, like all you witc...    1    0    1    0    1\n",
      "17  You twistedup my life and spit on all my dream...    1    0    1    0    1\n",
      "18                  Now come on shoot me set me free.    1    0    1    0    1\n",
      "19  I've got a lovely bunch of coconuts standing i...    1    0    1    0    1\n"
     ]
    }
   ],
   "source": [
    "print(train_data.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b5610e2-b295-487c-a97d-1a219e3c3884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'EXT', 'NEU', 'AGR', 'CON', 'OPN'],\n",
      "        num_rows: 73537\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'EXT', 'NEU', 'AGR', 'CON', 'OPN'],\n",
      "        num_rows: 25629\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['text', 'EXT', 'NEU', 'AGR', 'CON', 'OPN'],\n",
      "        num_rows: 23811\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Convert to DatasetDict\n",
    "train_dataset = Dataset.from_dict(train_data)\n",
    "test_dataset = Dataset.from_dict(test_data)\n",
    "valid_dataset = Dataset.from_dict(validation_data)\n",
    "\n",
    "full_dataset_dict = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"test\": test_dataset,\n",
    "    \"valid\": valid_dataset\n",
    "})\n",
    "\n",
    "print(full_dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deb5f7c-f394-4465-929e-e1461454c96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73537/73537 [00:10<00:00, 7230.63 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25629/25629 [00:03<00:00, 7800.78 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23811/23811 [00:03<00:00, 6991.84 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(row):\n",
    "\n",
    "    # Extract the text\n",
    "    essays = row['text']\n",
    "\n",
    "    # Clean up\n",
    "    essays = [dataset_processors.preprocess_text(essay) for essay in essays]\n",
    "\n",
    "    # Encode them using the tokenizer\n",
    "    encoded_essay = tokenizer(essays, truncation=True, max_length=256)\n",
    "    \n",
    "    # Add the labels\n",
    "    labels_batch = {key: row[key] for key in row.keys() if key in labels}\n",
    "\n",
    "    # Create numpy array of batch and labels\n",
    "    labels_matrix = np.zeros((len(essays), len(labels)))\n",
    "\n",
    "    # Fill the array\n",
    "    for idx, label in enumerate(labels):\n",
    "        labels_matrix[:, idx] = labels_batch[label]\n",
    "\n",
    "    # Return the encoding\n",
    "    encoded_essay[\"labels\"] = labels_matrix.tolist()\n",
    "    \n",
    "    return encoded_essay\n",
    "\n",
    "# Perform the preprocessing\n",
    "full_dataset_dict = full_dataset_dict.map(\n",
    "    preprocess_text, batched = True, \n",
    "    remove_columns = full_dataset_dict['train'].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ded205d-e53b-44a9-ab57-188113e2a2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [35, 569, 5020, 145, 9, 4, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1], 'labels': [1.0, 0.0, 1.0, 0.0, 1.0]}\n"
     ]
    }
   ],
   "source": [
    "#print(full_dataset_dict['train'][0].keys())\n",
    "print(full_dataset_dict['train'][0])\n",
    "#print(full_dataset_dict['train'][0]['labels'])\n",
    "#tokenizer.decode(full_dataset_dict['train'][5]['input_ids'])\n",
    "#[id2label[idx] for idx, label in enumerate(full_dataset_dict['train'][5]['labels']) if label == 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1fef2364-a4e1-4a29-a59e-1a63117fa6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset_dict.set_format(\"torch\", device=\"cuda:0\")\n",
    "model = model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a27c08f-62be-4ad9-a122-6315219f314b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "batch_size = 16\n",
    "learning_rate = 2e-5\n",
    "epochs = 10\n",
    "metric_name = \"accuracy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d50dae2b-2141-48cc-9223-4b2d593db6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\transformers\\training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    saved_model_file,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"no\",\n",
    "    learning_rate = learning_rate,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs = epochs,\n",
    "    weight_decay = 0.01,\n",
    "    metric_for_best_model = metric_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac86ae5e-1fae-443f-95f5-c830d55220d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EXT', 'NEU', 'AGR', 'CON', 'OPN']\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09a9ad32-4abf-45a6-b64d-5c0d2764dba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "\n",
    "def multi_label_metrics(pred_logits, gold_labels):\n",
    "\n",
    "    # Our threshold\n",
    "    threshold = 0.5\n",
    "\n",
    "    # Apply sigmoid to logits\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(pred_logits))\n",
    "\n",
    "    # Convert predictions to integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= threshold)] = 1\n",
    "\n",
    "    # Compute metrics\n",
    "    y_true = gold_labels\n",
    "\n",
    "    metrics = {\n",
    "        f\"{id2label[i]} - accuracy\": accuracy_score(y_true[:, i], y_pred[:, i]) \n",
    "        for i in range(len(labels))\n",
    "    }\n",
    "\n",
    "    overall_accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # Store and return as dictionary\n",
    "    metrics['accuracy'] = overall_accuracy\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def compute_metrics(p):\n",
    "\n",
    "    # Get the type of predictions\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "\n",
    "    # Compute the results\n",
    "    results = multi_label_metrics(preds, p.label_ids)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "79b0a251-1121-45eb-bc02-97c862854dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLNetForSequenceClassificationOutput(loss=tensor(0.7372, device='cuda:0',\n",
       "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), logits=tensor([[ 0.0788,  0.0643, -0.0348,  0.3570, -0.0282]], device='cuda:0',\n",
       "       grad_fn=<AddmmBackward0>), mems=None, hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass (testing)\n",
    "\n",
    "outputs = model(\n",
    "    input_ids=full_dataset_dict['train']['input_ids'][0].unsqueeze(0), \n",
    "    attention_mask=full_dataset_dict['train']['attention_mask'][0].unsqueeze(0),\n",
    "    labels=full_dataset_dict['train'][0]['labels'].unsqueeze(0),\n",
    "    use_mems=None\n",
    ")\n",
    "\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "47c47e55-bf4e-47f3-a8f5-5f02cb701f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the trainer before training\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=full_dataset_dict[\"train\"],\n",
    "    eval_dataset=full_dataset_dict[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0f249eb1-2fef-4493-868f-91ae530a9e35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 109/45970 [00:40<6:00:31,  2.12it/s]"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 360.00 MiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\transformers\\trainer.py:2052\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2050\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2051\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2052\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2057\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\transformers\\trainer.py:2388\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m   2387\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m-> 2388\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2391\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2392\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2393\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2394\u001b[0m ):\n\u001b[0;32m   2395\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2396\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\transformers\\trainer.py:3485\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   3482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   3484\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 3485\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3487\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[0;32m   3488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   3489\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3490\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   3491\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\transformers\\trainer.py:3532\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[0;32m   3530\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3531\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 3532\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m   3533\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[0;32m   3534\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[0;32m   3535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\transformers\\models\\xlnet\\modeling_xlnet.py:1541\u001b[0m, in \u001b[0;36mXLNetForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, mems, perm_mask, target_mapping, token_type_ids, input_mask, head_mask, inputs_embeds, labels, use_mems, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1533\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1534\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1535\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1539\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1541\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer(\n\u001b[0;32m   1542\u001b[0m     input_ids,\n\u001b[0;32m   1543\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   1544\u001b[0m     mems\u001b[38;5;241m=\u001b[39mmems,\n\u001b[0;32m   1545\u001b[0m     perm_mask\u001b[38;5;241m=\u001b[39mperm_mask,\n\u001b[0;32m   1546\u001b[0m     target_mapping\u001b[38;5;241m=\u001b[39mtarget_mapping,\n\u001b[0;32m   1547\u001b[0m     token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids,\n\u001b[0;32m   1548\u001b[0m     input_mask\u001b[38;5;241m=\u001b[39minput_mask,\n\u001b[0;32m   1549\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m   1550\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[0;32m   1551\u001b[0m     use_mems\u001b[38;5;241m=\u001b[39muse_mems,\n\u001b[0;32m   1552\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1553\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   1554\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1555\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1556\u001b[0m )\n\u001b[0;32m   1557\u001b[0m output \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1559\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msequence_summary(output)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\transformers\\models\\xlnet\\modeling_xlnet.py:1233\u001b[0m, in \u001b[0;36mXLNetModel.forward\u001b[1;34m(self, input_ids, attention_mask, mems, perm_mask, target_mapping, token_type_ids, input_mask, head_mask, inputs_embeds, use_mems, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[0;32m   1231\u001b[0m     hidden_states\u001b[38;5;241m.\u001b[39mappend((output_h, output_g) \u001b[38;5;28;01mif\u001b[39;00m output_g \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m output_h)\n\u001b[1;32m-> 1233\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1234\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_h\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1235\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_g\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask_h\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_tgt_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask_g\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1238\u001b[0m \u001b[43m    \u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_emb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseg_mat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseg_mat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1240\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmems\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmems\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1241\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1242\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1243\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1244\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1245\u001b[0m output_h, output_g \u001b[38;5;241m=\u001b[39m outputs[:\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m   1246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\transformers\\models\\xlnet\\modeling_xlnet.py:504\u001b[0m, in \u001b[0;36mXLNetLayer.forward\u001b[1;34m(self, output_h, output_g, attn_mask_h, attn_mask_g, r, seg_mat, mems, target_mapping, head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    492\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    493\u001b[0m     output_h,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    502\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    503\u001b[0m ):\n\u001b[1;32m--> 504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrel_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_h\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_g\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask_h\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask_g\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[43m        \u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseg_mat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmems\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmems\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    516\u001b[0m     output_h, output_g \u001b[38;5;241m=\u001b[39m outputs[:\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    518\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_g \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\transformers\\models\\xlnet\\modeling_xlnet.py:435\u001b[0m, in \u001b[0;36mXLNetRelativeAttention.forward\u001b[1;34m(self, h, g, attn_mask_h, attn_mask_g, r, seg_mat, mems, target_mapping, head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    432\u001b[0m k_head_r \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mibh,hnd->ibnd\u001b[39m\u001b[38;5;124m\"\u001b[39m, r\u001b[38;5;241m.\u001b[39mtype(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mr\u001b[38;5;241m.\u001b[39mdtype), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mr)\n\u001b[0;32m    434\u001b[0m \u001b[38;5;66;03m# core attention ops\u001b[39;00m\n\u001b[1;32m--> 435\u001b[0m attn_vec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrel_attn_core\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m    \u001b[49m\u001b[43mq_head_h\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk_head_h\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    438\u001b[0m \u001b[43m    \u001b[49m\u001b[43mv_head_h\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk_head_r\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseg_mat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseg_mat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask_h\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[0;32m    447\u001b[0m     attn_vec, attn_prob \u001b[38;5;241m=\u001b[39m attn_vec\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\transformers\\models\\xlnet\\modeling_xlnet.py:276\u001b[0m, in \u001b[0;36mXLNetRelativeAttention.rel_attn_core\u001b[1;34m(self, q_head, k_head_h, v_head_h, k_head_r, seg_mat, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    273\u001b[0m ac \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mibnd,jbnd->bnij\u001b[39m\u001b[38;5;124m\"\u001b[39m, q_head \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mr_w_bias, k_head_h)\n\u001b[0;32m    275\u001b[0m \u001b[38;5;66;03m# position based attention score\u001b[39;00m\n\u001b[1;32m--> 276\u001b[0m bd \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mibnd,jbnd->bnij\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq_head\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mr_r_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_head_r\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    277\u001b[0m bd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrel_shift_bnij(bd, klen\u001b[38;5;241m=\u001b[39mac\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m3\u001b[39m])\n\u001b[0;32m    279\u001b[0m \u001b[38;5;66;03m# segment based attention score\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\torch\\functional.py:385\u001b[0m, in \u001b[0;36meinsum\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m einsum(equation, \u001b[38;5;241m*\u001b[39m_operands)\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(operands) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39menabled:\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;66;03m# or the user has disabled using opt_einsum\u001b[39;00m\n\u001b[1;32m--> 385\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    387\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39mis_available():\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 360.00 MiB. GPU "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a2c753ad-e7a7-4b06-a603-c64cea740dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(saved_model_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
