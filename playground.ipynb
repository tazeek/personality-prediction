{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eefaf6b5-8d57-40d2-8412-3569af78d132",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets.dataset_dict import DatasetDict\n",
    "from datasets import Dataset\n",
    "\n",
    "import utils.dataset_processors as dataset_processors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f53784a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model name for tokenizer and also the saved model name\n",
    "model_name = 'distilbert-base-uncased'\n",
    "saved_model = 'distillbert-finetuned-segmented'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fb33c60-2870-4925-a7a6-d021c3f6ff01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "datafile = \"data/essays/essays.csv\"\n",
    "dataset = dataset_processors.load_essays_df(datafile)\n",
    "\n",
    "# Split the dataset (6:2:2)\n",
    "train_data, temp_data = train_test_split(dataset, train_size=0.6, random_state=42)\n",
    "validation_data, test_data = train_test_split(temp_data, train_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "454825b8-eb4a-499d-a7f7-2235941bd74a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EXT', 'NEU', 'AGR', 'CON', 'OPN']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the Big 5 labels\n",
    "column_names = list(train_data.columns)\n",
    "labels = [label for label in column_names if label not in ['user','text','token_len']]\n",
    "\n",
    "# Forward and backward mapping\n",
    "id2label = {idx:label for idx,label in enumerate(labels)}\n",
    "label2id = {label:idx for idx,label in enumerate(labels)}\n",
    "\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7193809",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Import the model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    problem_type = \"multi_label_classification\",\n",
    "    num_labels = len(labels),\n",
    "    id2label = id2label,\n",
    "    label2id = label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e37b9a3d-9c80-46e8-b6ce-3008f87373fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from essay to sentences\n",
    "def split_text_with_labels(row):\n",
    "    \n",
    "    # Split sentences\n",
    "    sentences = re.split(r\"(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|\\!)\\s\", row['text'])\n",
    "\n",
    "    return [{\n",
    "        'text': sentence,\n",
    "        'EXT': row['EXT'],\n",
    "        'NEU': row['NEU'],\n",
    "        'AGR': row['AGR'],\n",
    "        'CON': row['CON'],\n",
    "        'OPN': row['OPN']\n",
    "    }\n",
    "        for sentence in sentences       \n",
    "    ]\n",
    "\n",
    "def transform_dataframe(old_dataframe):\n",
    "\n",
    "    # Begin the split\n",
    "    split_data = []\n",
    "    \n",
    "    for _, row in old_dataframe.iterrows():\n",
    "        split_data.extend(split_text_with_labels(row))\n",
    "        \n",
    "    return pd.DataFrame(split_data)\n",
    "\n",
    "train_data = transform_dataframe(train_data)\n",
    "test_data = transform_dataframe(test_data)\n",
    "validation_data = transform_dataframe(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d724425-a30b-479b-bac7-c10b2cc9e875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text  EXT  NEU  AGR  CON  OPN\n",
      "0                                     I am tired now.    1    0    1    0    1\n",
      "1              I don't know what I should talk about.    1    0    1    0    1\n",
      "2                             I like this assignment.    1    0    1    0    1\n",
      "3                               Wonder when it's due?    1    0    1    0    1\n",
      "4    Kristi Urey is the most beautiful person I know.    1    0    1    0    1\n",
      "5                                         I love you.    1    0    1    0    1\n",
      "6   I mean I love her with all of my heart, mind, ...    1    0    1    0    1\n",
      "7                   I like psychology in high school.    1    0    1    0    1\n",
      "8               It was very interesting and personal.    1    0    1    0    1\n",
      "9                 That draws people in or so I think.    1    0    1    0    1\n",
      "10                 Psychology is the food of the sea.    1    0    1    0    1\n",
      "11                            My roommate's a weirdo.    1    0    1    0    1\n",
      "12             He wears a hat to watch Conan O'Brien.    1    0    1    0    1\n",
      "13  My other roommate got his computer from Dell t...    1    0    1    0    1\n",
      "14                                     I like Kristi.    1    0    1    0    1\n",
      "15  I may not be a smart man, but I know what love...    1    0    1    0    1\n",
      "16  Someone's going to be sorry, like all you witc...    1    0    1    0    1\n",
      "17  You twistedup my life and spit on all my dream...    1    0    1    0    1\n",
      "18                  Now come on shoot me set me free.    1    0    1    0    1\n",
      "19  I've got a lovely bunch of coconuts standing i...    1    0    1    0    1\n"
     ]
    }
   ],
   "source": [
    "print(train_data.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b5610e2-b295-487c-a97d-1a219e3c3884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'EXT', 'NEU', 'AGR', 'CON', 'OPN'],\n",
      "        num_rows: 73537\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'EXT', 'NEU', 'AGR', 'CON', 'OPN'],\n",
      "        num_rows: 25629\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['text', 'EXT', 'NEU', 'AGR', 'CON', 'OPN'],\n",
      "        num_rows: 23811\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Convert to DatasetDict\n",
    "train_dataset = Dataset.from_dict(train_data)\n",
    "test_dataset = Dataset.from_dict(test_data)\n",
    "valid_dataset = Dataset.from_dict(validation_data)\n",
    "\n",
    "full_dataset_dict = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"test\": test_dataset,\n",
    "    \"valid\": valid_dataset\n",
    "})\n",
    "\n",
    "print(full_dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0deb5f7c-f394-4465-929e-e1461454c96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73537/73537 [00:10<00:00, 7095.17 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25629/25629 [00:03<00:00, 6979.97 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23811/23811 [00:03<00:00, 6663.40 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(row):\n",
    "\n",
    "    # Extract the text\n",
    "    essays = row['text']\n",
    "\n",
    "    # Clean up\n",
    "    essays = [dataset_processors.preprocess_text(essay) for essay in essays]\n",
    "\n",
    "    # Encode them using the tokenizer\n",
    "    encoded_essay = tokenizer(essays, truncation=True)\n",
    "    \n",
    "    # Add the labels\n",
    "    labels_batch = {key: row[key] for key in row.keys() if key in labels}\n",
    "\n",
    "    # Create numpy array of batch and labels\n",
    "    labels_matrix = np.zeros((len(essays), len(labels)))\n",
    "\n",
    "    # Fill the array\n",
    "    for idx, label in enumerate(labels):\n",
    "        labels_matrix[:, idx] = labels_batch[label]\n",
    "\n",
    "    # Return the encoding\n",
    "    encoded_essay[\"labels\"] = labels_matrix.tolist()\n",
    "    \n",
    "    return encoded_essay\n",
    "\n",
    "# Perform the preprocessing\n",
    "full_dataset_dict = full_dataset_dict.map(\n",
    "    preprocess_text, batched = True, \n",
    "    remove_columns = full_dataset_dict['train'].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ded205d-e53b-44a9-ab57-188113e2a2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 1045, 2572, 5458, 2085, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1], 'labels': [1.0, 0.0, 1.0, 0.0, 1.0]}\n"
     ]
    }
   ],
   "source": [
    "#print(full_dataset_dict['train'][0].keys())\n",
    "print(full_dataset_dict['train'][0])\n",
    "#print(full_dataset_dict['train'][0]['labels'])\n",
    "#tokenizer.decode(full_dataset_dict['train'][5]['input_ids'])\n",
    "#[id2label[idx] for idx, label in enumerate(full_dataset_dict['train'][5]['labels']) if label == 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fef2364-a4e1-4a29-a59e-1a63117fa6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset_dict.set_format(\"torch\", device=\"cuda:0\")\n",
    "model = model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a27c08f-62be-4ad9-a122-6315219f314b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2e-05\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "batch_size = 16\n",
    "learning_rate = 2e-5\n",
    "epochs = 10\n",
    "metric_name = \"accuracy\"\n",
    "\n",
    "print(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d50dae2b-2141-48cc-9223-4b2d593db6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\transformers\\training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    saved_model,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"no\",\n",
    "    learning_rate = learning_rate,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs = epochs,\n",
    "    weight_decay = 0.01,\n",
    "    metric_for_best_model = metric_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac86ae5e-1fae-443f-95f5-c830d55220d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EXT', 'NEU', 'AGR', 'CON', 'OPN']\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09a9ad32-4abf-45a6-b64d-5c0d2764dba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "\n",
    "def multi_label_metrics(pred_logits, gold_labels):\n",
    "\n",
    "    # Our threshold\n",
    "    threshold = 0.5\n",
    "\n",
    "    # Apply sigmoid to logits\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(pred_logits))\n",
    "\n",
    "    # Convert predictions to integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= threshold)] = 1\n",
    "\n",
    "    # Compute metrics\n",
    "    y_true = gold_labels\n",
    "\n",
    "    metrics = {\n",
    "        f\"{id2label[i]} - accuracy\": accuracy_score(y_true[:, i], y_pred[:, i]) \n",
    "        for i in range(len(labels))\n",
    "    }\n",
    "\n",
    "    overall_accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # Store and return as dictionary\n",
    "    metrics['accuracy'] = overall_accuracy\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def compute_metrics(p):\n",
    "\n",
    "    # Get the type of predictions\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "\n",
    "    # Compute the results\n",
    "    results = multi_label_metrics(preds, p.label_ids)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79b0a251-1121-45eb-bc02-97c862854dbd",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# forward pass (testing)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_dataset_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_dataset_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_dataset_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m outputs\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:883\u001b[0m, in \u001b[0;36mDistilBertForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    881\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m--> 883\u001b[0m distilbert_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistilbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    892\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m distilbert_output[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, seq_len, dim)\u001b[39;00m\n\u001b[0;32m    893\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m hidden_state[:, \u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, dim)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:695\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    692\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m    693\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m--> 695\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m    697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_flash_attention_2:\n\u001b[0;32m    698\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m attention_mask \u001b[38;5;28;01mif\u001b[39;00m (attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01min\u001b[39;00m attention_mask) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:110\u001b[0m, in \u001b[0;36mEmbeddings.forward\u001b[1;34m(self, input_ids, input_embeds)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03m    input_ids (torch.Tensor):\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;124;03membeddings)\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 110\u001b[0m     input_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (bs, max_seq_length, dim)\u001b[39;00m\n\u001b[0;32m    112\u001b[0m seq_length \u001b[38;5;241m=\u001b[39m input_embeds\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# Setting the position-ids to the registered buffer in constructor, it helps\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;66;03m# when tracing the model without passing position-ids, solves\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m# isues similar to issue #5664\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\torch\\nn\\functional.py:2264\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2258\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2259\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2260\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2261\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2262\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2263\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)"
     ]
    }
   ],
   "source": [
    "# forward pass (testing)\n",
    "outputs = model(\n",
    "    input_ids=full_dataset_dict['train']['input_ids'][0].unsqueeze(0), \n",
    "    attention_mask=full_dataset_dict['train']['attention_mask'][0].unsqueeze(0),\n",
    "    labels=full_dataset_dict['train'][0]['labels'].unsqueeze(0)\n",
    ")\n",
    "\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c47e55-bf4e-47f3-a8f5-5f02cb701f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the trainer before training\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=full_dataset_dict[\"train\"],\n",
    "    eval_dataset=full_dataset_dict[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f249eb1-2fef-4493-868f-91ae530a9e35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 502/45970 [00:47<1:03:40, 11.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.691, 'grad_norm': 0.6273068189620972, 'learning_rate': 1.9782466826190996e-05, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 1001/45970 [01:37<1:04:23, 11.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6874, 'grad_norm': 0.5319086909294128, 'learning_rate': 1.956493365238199e-05, 'epoch': 0.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 1502/45970 [02:26<58:59, 12.56it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.688, 'grad_norm': 0.527271568775177, 'learning_rate': 1.9347400478572985e-05, 'epoch': 0.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|â–         | 2001/45970 [03:23<59:23, 12.34it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6865, 'grad_norm': 0.46152377128601074, 'learning_rate': 1.9129867304763977e-05, 'epoch': 0.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–Œ         | 2501/45970 [04:07<1:05:03, 11.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6864, 'grad_norm': 0.44222092628479004, 'learning_rate': 1.891233413095497e-05, 'epoch': 0.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|â–‹         | 3002/45970 [04:55<1:06:00, 10.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6853, 'grad_norm': 0.5859605669975281, 'learning_rate': 1.8694800957145966e-05, 'epoch': 0.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 3502/45970 [05:44<1:00:01, 11.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6854, 'grad_norm': 0.5201916694641113, 'learning_rate': 1.847726778333696e-05, 'epoch': 0.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|â–Š         | 4001/45970 [06:31<1:03:39, 10.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6842, 'grad_norm': 0.4794982969760895, 'learning_rate': 1.8259734609527955e-05, 'epoch': 0.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–‰         | 4502/45970 [07:20<54:39, 12.64it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6848, 'grad_norm': 0.5099848508834839, 'learning_rate': 1.804220143571895e-05, 'epoch': 0.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 4597/45970 [07:44<58:14, 11.84it/s]  \n",
      " 10%|â–ˆ         | 4598/45970 [08:13<75:04:26,  6.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6918413043022156, 'eval_EXT - accuracy': 0.5262007881696515, 'eval_NEU - accuracy': 0.525849623473409, 'eval_AGR - accuracy': 0.5238987084942838, 'eval_CON - accuracy': 0.5392719185297905, 'eval_OPN - accuracy': 0.5479339810371064, 'eval_accuracy': 0.04081314136329939, 'eval_runtime': 43.0002, 'eval_samples_per_second': 596.02, 'eval_steps_per_second': 37.256, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|â–ˆ         | 5001/45970 [08:55<1:15:44,  9.02it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6752, 'grad_norm': 0.8602599501609802, 'learning_rate': 1.7824668261909944e-05, 'epoch': 1.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|â–ˆâ–        | 5501/45970 [09:46<1:01:41, 10.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6715, 'grad_norm': 1.0399482250213623, 'learning_rate': 1.760713508810094e-05, 'epoch': 1.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|â–ˆâ–Ž        | 6002/45970 [10:44<59:12, 11.25it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6705, 'grad_norm': 0.8623043298721313, 'learning_rate': 1.738960191429193e-05, 'epoch': 1.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|â–ˆâ–        | 6500/45970 [11:31<55:19, 11.89it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6701, 'grad_norm': 0.9025463461875916, 'learning_rate': 1.7172068740482925e-05, 'epoch': 1.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|â–ˆâ–Œ        | 7002/45970 [12:16<54:22, 11.95it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.669, 'grad_norm': 0.8689930438995361, 'learning_rate': 1.695453556667392e-05, 'epoch': 1.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|â–ˆâ–‹        | 7502/45970 [13:02<51:21, 12.48it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6689, 'grad_norm': 1.208105444908142, 'learning_rate': 1.6737002392864914e-05, 'epoch': 1.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|â–ˆâ–‹        | 8002/45970 [13:49<56:31, 11.19it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6684, 'grad_norm': 1.156531572341919, 'learning_rate': 1.651946921905591e-05, 'epoch': 1.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|â–ˆâ–Š        | 8501/45970 [14:36<54:28, 11.46it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6682, 'grad_norm': 1.1387372016906738, 'learning_rate': 1.6301936045246903e-05, 'epoch': 1.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–‰        | 9001/45970 [15:23<56:02, 10.99it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6665, 'grad_norm': 1.193719506263733, 'learning_rate': 1.6084402871437898e-05, 'epoch': 1.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 9194/45970 [15:54<50:05, 12.24it/s]  \n",
      " 20%|â–ˆâ–ˆ        | 9195/45970 [16:25<66:11:46,  6.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7019850015640259, 'eval_EXT - accuracy': 0.5236255803972063, 'eval_NEU - accuracy': 0.5257325685746616, 'eval_AGR - accuracy': 0.5290881423387569, 'eval_CON - accuracy': 0.5339264114869874, 'eval_OPN - accuracy': 0.5407936322135082, 'eval_accuracy': 0.04795349018689766, 'eval_runtime': 42.634, 'eval_samples_per_second': 601.14, 'eval_steps_per_second': 37.576, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|â–ˆâ–ˆ        | 9502/45970 [16:52<56:32, 10.75it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6486, 'grad_norm': 2.006427049636841, 'learning_rate': 1.586686969762889e-05, 'epoch': 2.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|â–ˆâ–ˆâ–       | 10002/45970 [17:51<1:31:05,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6324, 'grad_norm': 1.8180471658706665, 'learning_rate': 1.5649336523819884e-05, 'epoch': 2.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|â–ˆâ–ˆâ–Ž       | 10503/45970 [18:44<48:56, 12.08it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6307, 'grad_norm': 2.0798797607421875, 'learning_rate': 1.543180335001088e-05, 'epoch': 2.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|â–ˆâ–ˆâ–       | 11002/45970 [19:29<49:10, 11.85it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6303, 'grad_norm': 3.033079147338867, 'learning_rate': 1.5214270176201873e-05, 'epoch': 2.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|â–ˆâ–ˆâ–Œ       | 11502/45970 [20:11<46:12, 12.43it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6304, 'grad_norm': 2.4744064807891846, 'learning_rate': 1.4996737002392868e-05, 'epoch': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|â–ˆâ–ˆâ–Œ       | 12001/45970 [20:59<51:00, 11.10it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6306, 'grad_norm': 2.2164857387542725, 'learning_rate': 1.477920382858386e-05, 'epoch': 2.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|â–ˆâ–ˆâ–‹       | 12501/45970 [21:47<50:34, 11.03it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6328, 'grad_norm': 2.3960671424865723, 'learning_rate': 1.4561670654774855e-05, 'epoch': 2.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|â–ˆâ–ˆâ–Š       | 13001/45970 [22:39<42:56, 12.80it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6309, 'grad_norm': 2.0830626487731934, 'learning_rate': 1.434413748096585e-05, 'epoch': 2.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|â–ˆâ–ˆâ–‰       | 13502/45970 [23:25<44:01, 12.29it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6305, 'grad_norm': 2.428934335708618, 'learning_rate': 1.4126604307156841e-05, 'epoch': 2.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–ˆ       | 13791/45970 [24:05<47:53, 11.20it/s]  \n",
      " 30%|â–ˆâ–ˆâ–ˆ       | 13792/45970 [24:33<56:50:51,  6.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7336689829826355, 'eval_EXT - accuracy': 0.5228452144055562, 'eval_NEU - accuracy': 0.5217136837176636, 'eval_AGR - accuracy': 0.5195286589410434, 'eval_CON - accuracy': 0.525303367279254, 'eval_OPN - accuracy': 0.5463732490538062, 'eval_accuracy': 0.04697803269733505, 'eval_runtime': 41.8309, 'eval_samples_per_second': 612.68, 'eval_steps_per_second': 38.297, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–ˆ       | 14001/45970 [24:55<45:40, 11.66it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6093, 'grad_norm': 2.4835166931152344, 'learning_rate': 1.3909071133347836e-05, 'epoch': 3.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|â–ˆâ–ˆâ–ˆâ–      | 14500/45970 [25:47<54:38,  9.60it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5762, 'grad_norm': 2.3108561038970947, 'learning_rate': 1.369153795953883e-05, 'epoch': 3.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 15001/45970 [26:37<42:29, 12.15it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5837, 'grad_norm': 2.8878633975982666, 'learning_rate': 1.3474004785729825e-05, 'epoch': 3.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 15501/45970 [27:25<40:10, 12.64it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5797, 'grad_norm': 4.083866596221924, 'learning_rate': 1.3256471611920818e-05, 'epoch': 3.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|â–ˆâ–ˆâ–ˆâ–      | 16002/45970 [28:13<41:37, 12.00it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5797, 'grad_norm': 3.1972618103027344, 'learning_rate': 1.3038938438111812e-05, 'epoch': 3.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16502/45970 [28:58<46:29, 10.57it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.585, 'grad_norm': 3.7651357650756836, 'learning_rate': 1.2821405264302807e-05, 'epoch': 3.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 17003/45970 [29:47<40:01, 12.06it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5829, 'grad_norm': 4.923808574676514, 'learning_rate': 1.26038720904938e-05, 'epoch': 3.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 17501/45970 [30:30<38:58, 12.17it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5836, 'grad_norm': 3.0999486446380615, 'learning_rate': 1.2386338916684794e-05, 'epoch': 3.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 18001/45970 [31:16<2:25:09,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5858, 'grad_norm': 3.529186725616455, 'learning_rate': 1.2168805742875789e-05, 'epoch': 3.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18388/45970 [32:15<46:51,  9.81it/s]  \n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18389/45970 [32:39<48:55:32,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.782143235206604, 'eval_EXT - accuracy': 0.5203090249326935, 'eval_NEU - accuracy': 0.5275664286550392, 'eval_AGR - accuracy': 0.5170314877677631, 'eval_CON - accuracy': 0.5219868118147412, 'eval_OPN - accuracy': 0.5438760778805259, 'eval_accuracy': 0.04615864840610246, 'eval_runtime': 41.9444, 'eval_samples_per_second': 611.023, 'eval_steps_per_second': 38.193, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18501/45970 [32:49<40:22, 11.34it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5696, 'grad_norm': 3.552867889404297, 'learning_rate': 1.1951272569066784e-05, 'epoch': 4.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19001/45970 [33:39<41:31, 10.83it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5243, 'grad_norm': 4.614861488342285, 'learning_rate': 1.1733739395257777e-05, 'epoch': 4.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19502/45970 [34:21<39:07, 11.28it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5305, 'grad_norm': 4.2878241539001465, 'learning_rate': 1.1516206221448771e-05, 'epoch': 4.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20003/45970 [35:13<31:57, 13.54it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5355, 'grad_norm': 4.105475902557373, 'learning_rate': 1.1298673047639766e-05, 'epoch': 4.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20502/45970 [36:04<37:43, 11.25it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5251, 'grad_norm': 3.9235007762908936, 'learning_rate': 1.108113987383076e-05, 'epoch': 4.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21001/45970 [36:51<37:12, 11.18it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5319, 'grad_norm': 4.30959939956665, 'learning_rate': 1.0863606700021753e-05, 'epoch': 4.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 21502/45970 [37:40<32:17, 12.63it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5338, 'grad_norm': 5.0950846672058105, 'learning_rate': 1.0646073526212748e-05, 'epoch': 4.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22002/45970 [38:27<33:17, 12.00it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5356, 'grad_norm': 4.265661239624023, 'learning_rate': 1.0428540352403743e-05, 'epoch': 4.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 22502/45970 [39:14<33:49, 11.56it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5324, 'grad_norm': 4.905956268310547, 'learning_rate': 1.0211007178594735e-05, 'epoch': 4.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 22985/45970 [40:16<52:54,  7.24it/s]  \n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 22986/45970 [40:44<49:23:06,  7.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8464130163192749, 'eval_EXT - accuracy': 0.5162121034765305, 'eval_NEU - accuracy': 0.515938975379453, 'eval_AGR - accuracy': 0.5143782433961528, 'eval_CON - accuracy': 0.520738226228101, 'eval_OPN - accuracy': 0.5349408872761325, 'eval_accuracy': 0.048616801279800226, 'eval_runtime': 41.8004, 'eval_samples_per_second': 613.128, 'eval_steps_per_second': 38.325, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23002/45970 [40:45<2:49:57,  2.25it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5291, 'grad_norm': 4.816239356994629, 'learning_rate': 9.99347400478573e-06, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23500/45970 [41:32<57:53,  6.47it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4789, 'grad_norm': 4.138972282409668, 'learning_rate': 9.775940830976725e-06, 'epoch': 5.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24002/45970 [42:23<31:34, 11.59it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4852, 'grad_norm': 5.230184078216553, 'learning_rate': 9.55840765716772e-06, 'epoch': 5.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 24502/45970 [43:16<28:44, 12.45it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4803, 'grad_norm': 4.789518356323242, 'learning_rate': 9.340874483358712e-06, 'epoch': 5.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25002/45970 [44:10<30:26, 11.48it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4777, 'grad_norm': 3.9592678546905518, 'learning_rate': 9.123341309549707e-06, 'epoch': 5.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 25502/45970 [44:58<33:37, 10.14it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4831, 'grad_norm': 7.437893867492676, 'learning_rate': 8.905808135740701e-06, 'epoch': 5.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26002/45970 [45:46<26:59, 12.33it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4853, 'grad_norm': 4.1771979331970215, 'learning_rate': 8.688274961931696e-06, 'epoch': 5.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 26501/45970 [46:31<30:02, 10.80it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4817, 'grad_norm': 5.542566299438477, 'learning_rate': 8.470741788122689e-06, 'epoch': 5.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27001/45970 [47:19<28:38, 11.04it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4841, 'grad_norm': 4.553526401519775, 'learning_rate': 8.253208614313684e-06, 'epoch': 5.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 27501/45970 [48:00<25:57, 11.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4818, 'grad_norm': 3.8263072967529297, 'learning_rate': 8.035675440504678e-06, 'epoch': 5.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 27582/45970 [48:26<26:38, 11.50it/s]\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 27583/45970 [48:50<39:45:39,  7.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9326357245445251, 'eval_EXT - accuracy': 0.516407194974443, 'eval_NEU - accuracy': 0.5164462132740255, 'eval_AGR - accuracy': 0.5155097740840454, 'eval_CON - accuracy': 0.5217917203168286, 'eval_OPN - accuracy': 0.5352530336727925, 'eval_accuracy': 0.04471497132154981, 'eval_runtime': 42.0198, 'eval_samples_per_second': 609.927, 'eval_steps_per_second': 38.125, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28001/45970 [49:32<25:40, 11.67it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.443, 'grad_norm': 5.769805431365967, 'learning_rate': 7.818142266695671e-06, 'epoch': 6.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 28501/45970 [50:19<26:44, 10.89it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4391, 'grad_norm': 5.021852016448975, 'learning_rate': 7.600609092886666e-06, 'epoch': 6.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29002/45970 [51:04<23:07, 12.23it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.438, 'grad_norm': 4.7704620361328125, 'learning_rate': 7.38307591907766e-06, 'epoch': 6.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29501/45970 [51:53<24:32, 11.18it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4401, 'grad_norm': 6.7290778160095215, 'learning_rate': 7.165542745268654e-06, 'epoch': 6.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 30003/45970 [52:41<1:21:22,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4385, 'grad_norm': 5.03167724609375, 'learning_rate': 6.948009571459649e-06, 'epoch': 6.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 30501/45970 [53:34<20:00, 12.89it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.442, 'grad_norm': 6.766926288604736, 'learning_rate': 6.7304763976506424e-06, 'epoch': 6.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31002/45970 [54:25<22:07, 11.27it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4404, 'grad_norm': 6.841715335845947, 'learning_rate': 6.512943223841637e-06, 'epoch': 6.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 31501/45970 [55:11<20:00, 12.05it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4357, 'grad_norm': 6.853383541107178, 'learning_rate': 6.295410050032631e-06, 'epoch': 6.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 32001/45970 [55:55<19:15, 12.09it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4414, 'grad_norm': 6.311779499053955, 'learning_rate': 6.0778768762236254e-06, 'epoch': 6.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 32179/45970 [56:26<56:35,  4.06it/s]  \n",
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 32180/45970 [56:56<26:11:07,  6.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0016638040542603, 'eval_EXT - accuracy': 0.5140270786999103, 'eval_NEU - accuracy': 0.5143392250965703, 'eval_AGR - accuracy': 0.5144562799953178, 'eval_CON - accuracy': 0.5196457138397909, 'eval_OPN - accuracy': 0.5375941316477428, 'eval_accuracy': 0.04424675172655976, 'eval_runtime': 41.9603, 'eval_samples_per_second': 610.792, 'eval_steps_per_second': 38.179, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 32502/45970 [57:24<20:17, 11.06it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4131, 'grad_norm': 6.8449320793151855, 'learning_rate': 5.860343702414619e-06, 'epoch': 7.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 33002/45970 [58:11<19:03, 11.34it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4043, 'grad_norm': 4.878905296325684, 'learning_rate': 5.642810528605612e-06, 'epoch': 7.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 33503/45970 [58:57<16:49, 12.35it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4008, 'grad_norm': 5.9229736328125, 'learning_rate': 5.425277354796607e-06, 'epoch': 7.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34002/45970 [59:47<15:46, 12.65it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4047, 'grad_norm': 6.516345500946045, 'learning_rate': 5.2077441809876005e-06, 'epoch': 7.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 34502/45970 [1:00:34<14:34, 13.12it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4053, 'grad_norm': 5.588491916656494, 'learning_rate': 4.990211007178595e-06, 'epoch': 7.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35001/45970 [1:01:19<18:20,  9.97it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4038, 'grad_norm': 8.990118980407715, 'learning_rate': 4.77267783336959e-06, 'epoch': 7.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 35503/45970 [1:02:10<13:14, 13.18it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4032, 'grad_norm': 5.471193790435791, 'learning_rate': 4.5551446595605835e-06, 'epoch': 7.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 36001/45970 [1:03:04<54:17,  3.06it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4009, 'grad_norm': 3.918320655822754, 'learning_rate': 4.337611485751577e-06, 'epoch': 7.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 36501/45970 [1:03:51<13:13, 11.93it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4025, 'grad_norm': 6.463129043579102, 'learning_rate': 4.120078311942571e-06, 'epoch': 7.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 36776/45970 [1:04:37<17:00,  9.01it/s]  \n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 36777/45970 [1:05:03<16:29:49,  6.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0700851678848267, 'eval_EXT - accuracy': 0.5145733348940653, 'eval_NEU - accuracy': 0.5151976276873854, 'eval_AGR - accuracy': 0.5131686761090951, 'eval_CON - accuracy': 0.5183581099535682, 'eval_OPN - accuracy': 0.5377111865464903, 'eval_accuracy': 0.04537828241445238, 'eval_runtime': 42.2722, 'eval_samples_per_second': 606.285, 'eval_steps_per_second': 37.897, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 37002/45970 [1:05:22<13:34, 11.01it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3899, 'grad_norm': 7.184511184692383, 'learning_rate': 3.902545138133566e-06, 'epoch': 8.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 37502/45970 [1:06:11<11:53, 11.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3775, 'grad_norm': 8.467717170715332, 'learning_rate': 3.68501196432456e-06, 'epoch': 8.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 38001/45970 [1:07:02<34:00,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3771, 'grad_norm': 9.418878555297852, 'learning_rate': 3.467478790515554e-06, 'epoch': 8.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38502/45970 [1:07:52<10:02, 12.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3689, 'grad_norm': 7.6100921630859375, 'learning_rate': 3.2499456167065478e-06, 'epoch': 8.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39002/45970 [1:08:41<12:51,  9.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3735, 'grad_norm': 7.055738925933838, 'learning_rate': 3.032412442897542e-06, 'epoch': 8.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 39502/45970 [1:09:32<09:10, 11.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3768, 'grad_norm': 8.992749214172363, 'learning_rate': 2.814879269088536e-06, 'epoch': 8.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 40002/45970 [1:10:23<08:06, 12.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3742, 'grad_norm': 6.056766510009766, 'learning_rate': 2.5973460952795303e-06, 'epoch': 8.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 40502/45970 [1:11:13<07:07, 12.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3778, 'grad_norm': 6.803421497344971, 'learning_rate': 2.3798129214705245e-06, 'epoch': 8.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 41002/45970 [1:11:56<06:56, 11.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3732, 'grad_norm': 4.9665846824646, 'learning_rate': 2.1622797476615183e-06, 'epoch': 8.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 41373/45970 [1:12:39<05:29, 13.94it/s]\n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 41374/45970 [1:13:08<9:20:32,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1256890296936035, 'eval_EXT - accuracy': 0.5146513714932304, 'eval_NEU - accuracy': 0.5135588591049202, 'eval_AGR - accuracy': 0.511764017324125, 'eval_CON - accuracy': 0.5192555308439658, 'eval_OPN - accuracy': 0.5365016192594326, 'eval_accuracy': 0.04483202622029732, 'eval_runtime': 41.0144, 'eval_samples_per_second': 624.878, 'eval_steps_per_second': 39.059, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 41502/45970 [1:13:19<05:54, 12.59it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3737, 'grad_norm': 10.302719116210938, 'learning_rate': 1.9447465738525125e-06, 'epoch': 9.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 42002/45970 [1:14:12<13:02,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3496, 'grad_norm': 6.177398681640625, 'learning_rate': 1.7272134000435066e-06, 'epoch': 9.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 42501/45970 [1:14:56<06:06,  9.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3508, 'grad_norm': 7.236640930175781, 'learning_rate': 1.5096802262345008e-06, 'epoch': 9.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 43002/45970 [1:15:43<04:39, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3552, 'grad_norm': 5.569890975952148, 'learning_rate': 1.292147052425495e-06, 'epoch': 9.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 43503/45970 [1:16:27<03:07, 13.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3531, 'grad_norm': 7.129018306732178, 'learning_rate': 1.074613878616489e-06, 'epoch': 9.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 44002/45970 [1:17:12<02:50, 11.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3531, 'grad_norm': 9.848424911499023, 'learning_rate': 8.570807048074832e-07, 'epoch': 9.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 44502/45970 [1:18:02<02:20, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3585, 'grad_norm': 7.727417469024658, 'learning_rate': 6.395475309984774e-07, 'epoch': 9.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 45002/45970 [1:18:50<01:18, 12.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3512, 'grad_norm': 6.670873641967773, 'learning_rate': 4.2201435718947146e-07, 'epoch': 9.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 45503/45970 [1:19:38<00:36, 12.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3586, 'grad_norm': 6.320346832275391, 'learning_rate': 2.0448118338046557e-07, 'epoch': 9.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45970/45970 [1:20:37<00:00, 11.85it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45970/45970 [1:21:05<00:00,  9.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.169968605041504, 'eval_EXT - accuracy': 0.5155878106832105, 'eval_NEU - accuracy': 0.5146123531936478, 'eval_AGR - accuracy': 0.5128175114128526, 'eval_CON - accuracy': 0.5185532014514808, 'eval_OPN - accuracy': 0.5367357290569277, 'eval_accuracy': 0.04448086152405478, 'eval_runtime': 40.0307, 'eval_samples_per_second': 640.234, 'eval_steps_per_second': 40.019, 'epoch': 10.0}\n",
      "{'train_runtime': 4865.7421, 'train_samples_per_second': 151.132, 'train_steps_per_second': 9.448, 'train_loss': 0.5153251616415937, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=45970, training_loss=0.5153251616415937, metrics={'train_runtime': 4865.7421, 'train_samples_per_second': 151.132, 'train_steps_per_second': 9.448, 'total_flos': 9631412851951230.0, 'train_loss': 0.5153251616415937, 'epoch': 10.0})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c753ad-e7a7-4b06-a603-c64cea740dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('fine-tuned-roberta-personality-normal')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
