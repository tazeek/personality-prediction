{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db878dec-2a72-43c1-9b4a-ad19e52ebd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_text import LimeTextExplainer\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "from random import randrange\n",
    "import utils.dataset_processors as dataset_processors\n",
    "from sota_list import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83787f14-212d-4a35-9e60-a21935172b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the finetuned BERT model\n",
    "\n",
    "config = AutoConfig.from_pretrained('fine-tuned-bert-personality-sentence-segmentation', output_hidden_states =True)\n",
    "bert_model = AutoModelForSequenceClassification.from_pretrained('fine-tuned-bert-personality-sentence-segmentation', config=config)\n",
    "tokenizer = AutoTokenizer.from_pretrained('fine-tuned-bert-personality-sentence-segmentation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c72adb9e-8f65-43cc-8d67-895d9cf04af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMNetwork(\n",
      "  (lstm): LSTM(768, 128, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load the trained LSTM model\n",
    "model_type = 'lstm'\n",
    "train_type = 'segmented'\n",
    "file_name = f\"finetuned_saved_models/{model_type}_{train_type}.pth\"\n",
    "\n",
    "persona_model = LSTMNetwork(768,128,5)\n",
    "persona_model.load_state_dict(torch.load(f\"{file_name}\"))\n",
    "persona_model.eval()\n",
    "print(persona_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd2de82-c853-4555-a26d-0cceee5c2b14",
   "metadata": {},
   "source": [
    "# Essays\n",
    "\n",
    "- Pick the ones with less than 512 tokens\n",
    "- Check the gold labels\n",
    "- Check the predicted labels\n",
    "- Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97ef3049-db78-4fa1-ad49-2e0af1494011",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (800 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXT :  EXT\n",
      "1    1275\n",
      "0    1192\n",
      "Name: count, dtype: int64\n",
      "NEU :  NEU\n",
      "1    1234\n",
      "0    1233\n",
      "Name: count, dtype: int64\n",
      "AGR :  AGR\n",
      "1    1309\n",
      "0    1158\n",
      "Name: count, dtype: int64\n",
      "CON :  CON\n",
      "1    1254\n",
      "0    1213\n",
      "Name: count, dtype: int64\n",
      "OPN :  OPN\n",
      "1    1271\n",
      "0    1196\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "\n",
      "              user                                               text  \\\n",
      "0  1997_971112.txt  alright. what can I talk about. well the only ...   \n",
      "1  1998_659134.txt  this job is going to drain me if I don't say s...   \n",
      "2  1998_045186.txt  I want to go to Mexico and dance I have not da...   \n",
      "3  1998_082105.txt  Is there a reason?  These questions have been ...   \n",
      "4  1999_973407.txt  For the past few days and now I have been thin...   \n",
      "5  2002_805223.txt       cold air quietness stress sad unreal comp...   \n",
      "6  1997_491971.txt  I hope I can finish this assignment in time be...   \n",
      "7  1998_494559.txt  I believe sometimes I think to much about what...   \n",
      "8  1997_953451.txt  My roommate won't shut up. O. K. Bert. My frie...   \n",
      "9  1999_741261.txt  I keep thinking about the future and how my li...   \n",
      "\n",
      "  token_len EXT NEU AGR CON OPN  \n",
      "0        43   1   0   1   1   1  \n",
      "1        51   1   0   1   0   1  \n",
      "2        68   0   1   1   1   1  \n",
      "3       117   0   0   1   1   1  \n",
      "4       132   0   1   0   1   0  \n",
      "5       167   1   0   1   0   0  \n",
      "6       171   0   1   0   0   1  \n",
      "7       173   1   1   1   1   0  \n",
      "8       181   1   0   1   1   1  \n",
      "9       182   0   1   0   0   0  \n"
     ]
    }
   ],
   "source": [
    "# Load the dataset and pre-process\n",
    "datafile = \"data/essays/essays.csv\"\n",
    "dataset = dataset_processors.load_essays_df(datafile)\n",
    "\n",
    "# sorting all essays in ascending order of their length\n",
    "for ind in dataset.index:\n",
    "    tokens = tokenizer.tokenize(dataset[\"text\"][ind])\n",
    "    dataset.at[ind, \"token_len\"] = len(tokens)\n",
    "\n",
    "dataset.sort_values(by=[\"token_len\", \"user\"], inplace=True, ascending=True, ignore_index=True)\n",
    "print(dataset.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e81a9e42-a060-4967-aa01-87124f3e9400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter those less than a limit\n",
    "limit = 100\n",
    "filtered_dataset = dataset[dataset['token_len'] <= limit]\n",
    "num_rows = len(filtered_dataset)\n",
    "num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cb59892-f7d0-48ae-9ba2-18d128c8a8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to go to Mexico and dance I have not dance in a wile no time the is so much good live music here it because money though I am hopefully going to get a job I need to turn in that application tomorrow too I have a lot of stuff to do oh well I am going take it as it comes though bye. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>token_len</th>\n",
       "      <th>EXT</th>\n",
       "      <th>NEU</th>\n",
       "      <th>AGR</th>\n",
       "      <th>CON</th>\n",
       "      <th>OPN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998_045186.txt</td>\n",
       "      <td>I want to go to Mexico and dance I have not da...</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              user                                               text  \\\n",
       "2  1998_045186.txt  I want to go to Mexico and dance I have not da...   \n",
       "\n",
       "  token_len EXT NEU AGR CON OPN  \n",
       "2        68   0   1   1   1   1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_num = randrange(num_rows)\n",
    "sample = filtered_dataset['text'][rand_num]\n",
    "print(sample)\n",
    "\n",
    "filtered_dataset.iloc[[rand_num]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ae6a4c5-34cb-49a2-a1ed-66060b37e1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['EXT', 'NEU', 'AGR', 'CON', 'OPN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5429c822-175a-4e2a-ac38-c7d9bd4f377b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the function to fetch the probability scores\n",
    "def get_proba_scores(texts):\n",
    "\n",
    "    # Tokenize\n",
    "    # NOTE: This is for just one input.\n",
    "    # Let's adapt for future ones\n",
    "    tokenized = tokenizer(texts, \n",
    "                padding = True,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True)\n",
    "\n",
    "    # Get the output logits and convert to scores\n",
    "    bert_output = bert_model(**tokenized)\n",
    "    cls_embedding = bert_output.hidden_states[-1][0,0,:]\n",
    "    cls_embedding = cls_embedding.unsqueeze(0)\n",
    "    \n",
    "    probability = persona_model(cls_embedding)\n",
    "    return probability.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca64ad1f-b8e5-45f6-b3f5-543bd5ecc46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.06544005 0.9209875  0.65194625 0.82494074 0.90769947]]\n"
     ]
    }
   ],
   "source": [
    "proba = get_proba_scores(sample)\n",
    "print(proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a02721cf-5842-4c99-a661-0f6869717e9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [25, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m explainer \u001b[38;5;241m=\u001b[39m LimeTextExplainer(class_names\u001b[38;5;241m=\u001b[39mclass_names)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Explain the instance passed in\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m explain_bert_output \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_instance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_proba_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Show the output in notebook\u001b[39;00m\n\u001b[0;32m     12\u001b[0m explain_bert_output\u001b[38;5;241m.\u001b[39mshow_in_notebook(text\u001b[38;5;241m=\u001b[39msample)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch-projects\\lib\\site-packages\\lime\\lime_text.py:429\u001b[0m, in \u001b[0;36mLimeTextExplainer.explain_instance\u001b[1;34m(self, text_instance, classifier_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001b[0m\n\u001b[0;32m    425\u001b[0m     ret_exp\u001b[38;5;241m.\u001b[39mtop_labels\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m labels:\n\u001b[0;32m    427\u001b[0m     (ret_exp\u001b[38;5;241m.\u001b[39mintercept[label],\n\u001b[0;32m    428\u001b[0m      ret_exp\u001b[38;5;241m.\u001b[39mlocal_exp[label],\n\u001b[1;32m--> 429\u001b[0m      ret_exp\u001b[38;5;241m.\u001b[39mscore, ret_exp\u001b[38;5;241m.\u001b[39mlocal_pred) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_instance_with_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistances\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_regressor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_regressor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_selection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_selection\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret_exp\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch-projects\\lib\\site-packages\\lime\\lime_base.py:183\u001b[0m, in \u001b[0;36mLimeBase.explain_instance_with_data\u001b[1;34m(self, neighborhood_data, neighborhood_labels, distances, label, num_features, feature_selection, model_regressor)\u001b[0m\n\u001b[0;32m    181\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_fn(distances)\n\u001b[0;32m    182\u001b[0m labels_column \u001b[38;5;241m=\u001b[39m neighborhood_labels[:, label]\n\u001b[1;32m--> 183\u001b[0m used_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_selection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneighborhood_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mlabels_column\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mfeature_selection\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_regressor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    189\u001b[0m     model_regressor \u001b[38;5;241m=\u001b[39m Ridge(alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, fit_intercept\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    190\u001b[0m                             random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch-projects\\lib\\site-packages\\lime\\lime_base.py:134\u001b[0m, in \u001b[0;36mLimeBase.feature_selection\u001b[1;34m(self, data, labels, weights, num_features, method)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    133\u001b[0m     n_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhighest_weights\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_selection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_method\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch-projects\\lib\\site-packages\\lime\\lime_base.py:80\u001b[0m, in \u001b[0;36mLimeBase.feature_selection\u001b[1;34m(self, data, labels, weights, num_features, method)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhighest_weights\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     78\u001b[0m     clf \u001b[38;5;241m=\u001b[39m Ridge(alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, fit_intercept\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     79\u001b[0m                 random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n\u001b[1;32m---> 80\u001b[0m     \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m     coef \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mcoef_\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sp\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39missparse(data):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch-projects\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch-projects\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:1123\u001b[0m, in \u001b[0;36mRidge.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit Ridge regression model.\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m \n\u001b[0;32m   1105\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;124;03m    Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1122\u001b[0m _accept_sparse \u001b[38;5;241m=\u001b[39m _get_valid_accept_sparse(sparse\u001b[38;5;241m.\u001b[39missparse(X), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msolver)\n\u001b[1;32m-> 1123\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1125\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1126\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_accept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1129\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1130\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch-projects\\lib\\site-packages\\sklearn\\base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    620\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 622\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    623\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch-projects\\lib\\site-packages\\sklearn\\utils\\validation.py:1164\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1146\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1147\u001b[0m     X,\n\u001b[0;32m   1148\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1159\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1160\u001b[0m )\n\u001b[0;32m   1162\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m-> 1164\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch-projects\\lib\\site-packages\\sklearn\\utils\\validation.py:407\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    405\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    408\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    409\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    410\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [25, 1]"
     ]
    }
   ],
   "source": [
    "# Create the explainer object\n",
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "\n",
    "# Explain the instance passed in\n",
    "explain_bert_output = explainer.explain_instance(\n",
    "    sample, get_proba_scores, \n",
    "    num_features = 10, num_samples = 25,\n",
    "    top_labels = 5\n",
    ")\n",
    "\n",
    "# Show the output in notebook\n",
    "explain_bert_output.show_in_notebook(text=sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cf2c43-9d0c-4b5b-9849-e7312231d664",
   "metadata": {},
   "source": [
    "# DailyDialog\n",
    "\n",
    "- Load the dataset\n",
    "- Pick conversation, then utterance\n",
    "- Pre-process and guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1af79484-2e11-48f7-8588-baf5ece52bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import codecs\n",
    "\n",
    "def load_dataset(portion_set):\n",
    "     \n",
    "    file_directory = f\"dataset_erc/dailydialogue/{portion_set}.json\"\n",
    "\n",
    "    train_file = []\n",
    "\n",
    "    with codecs.open(file_directory, \"r\", \"utf-8\") as f:\n",
    "        train_file = json.load(f)\n",
    "\n",
    "    return train_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0bf2ef41-ea5f-4308-8b96-80ab8de0d460",
   "metadata": {},
   "outputs": [],
   "source": [
    "portion_set = \"train\"\n",
    "dataset = load_dataset(portion_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6593dcef-9bff-46f8-8ce2-0c04c2efa9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'utterance': 'you are under arrest , sir . you have the right to remain silent . you better not pout , you better not cry . anything you say can and will be used against you . you have the right to an attorney . if you cannot afford one , the state will appoint one for you.do you understand the arrest to you ?',\n",
       " 'sentiment': '0',\n",
       " 'act': '1'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_conv = len(dataset)\n",
    "conv = dataset[randrange(num_conv)]\n",
    "\n",
    "num_utterances = len(conv)\n",
    "sample = conv[randrange(num_utterances)]\n",
    "\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35c3ca05-0e08-45c4-bd74-4c97658b27d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33714816 0.24806674 0.9022168  0.6177298  0.67106724]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['EXT', 'NEU', 'AGR', 'CON', 'OPN']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba = get_proba_scores(utterance['utterance'])\n",
    "print(proba)\n",
    "class_names = ['EXT', 'NEU', 'AGR', 'CON', 'OPN']\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9e7fe7-910d-4cec-98c2-c34e74c790f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
